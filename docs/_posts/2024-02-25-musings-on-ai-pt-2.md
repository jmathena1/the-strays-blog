---
layout: post-the-strays
author: John Mathena
---

Though I don't feel anything from pt 1 was incorrect, I wanted lend a bit more credulity to AI and Machine Learning work. I'm gonna reference mostly work and posts from
a machine learning engineer and tech writer I follow, Vicki Boykis. She has a great post from Feb 2023 on Chat GPT titled 
["What should you use Chat GPT for?"](https://vickiboykis.com/2023/02/26/what-should-you-use-chatgpt-for). Part of her assessment from then:
> "So, for myself, my rules for engaging with Chat GPT are to give it small, inconsequential things it can iterate well on and that I have the ability to check..."
I think I saw Kareem Carr say something similar on Twitter (also a great follow if you're not already).  

Seems a good assessment. And this coming from someone with a lot of experience with software as a whole and machine learning in particular. Now I've also seen some
(mostly on Twitter though again) compare the advent of LLM based coding tools to compilers. That doesn't quite sit right with me. I don't have a CS degree nor have I
event taken a CS class, but I've been programming for the better part of a decade (professionally for about five years) and I can read so I'm gonna try to break down
why. Maybe I'll look back on this series in 10 years and cringe but whatever at least I tried.

Compilers essentially translate code written in one language into another language.
